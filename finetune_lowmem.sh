#!/bin/bash

# æ¿€æ´» conda ç¯å¢ƒ
source ~/miniconda3/etc/profile.d/conda.sh
conda activate rdt

# ==========================================
# RDT-1B å¾®è°ƒè„šæœ¬ - ä½æ˜¾å­˜ä¼˜åŒ–ç‰ˆæœ¬
# é€‚ç”¨äº: RTX 4090 16GB
# ==========================================

# æ¨¡å‹è·¯å¾„é…ç½®
export TEXT_ENCODER_NAME="google/t5-v1_1-xxl"
export VISION_ENCODER_NAME="google/siglip-so400m-patch14-384"
export OUTPUT_DIR="./checkpoints/rdt-1b-stack-blocks"

# Wandb é…ç½®ï¼ˆå¯é€‰ï¼‰
export WANDB_PROJECT="rdt-stack-blocks-finetune"

# PyTorch å†…å­˜ä¼˜åŒ–
export PYTORCH_CUDA_ALLOC_CONF="max_split_size_mb:128"

# åˆ›å»ºè¾“å‡ºç›®å½•
if [ ! -d "$OUTPUT_DIR" ]; then
    mkdir -p "$OUTPUT_DIR"
    echo "âœ… åˆ›å»ºè¾“å‡ºç›®å½•: '$OUTPUT_DIR'"
else
    echo "ğŸ“ è¾“å‡ºç›®å½•å·²å­˜åœ¨: '$OUTPUT_DIR'"
fi

echo "================================================"
echo "ğŸš€ RDT-1B å¾®è°ƒ - ä½æ˜¾å­˜ä¼˜åŒ–ç‰ˆæœ¬"
echo "================================================"
echo "ğŸ’¾ æ•°æ®é›†: stack_blocks_three (50 episodes)"
echo "ğŸ’» GPU: RTX 4090 (16GB)"
echo "ğŸ”§ ä¼˜åŒ–ç­–ç•¥:"
echo "   - Batch Size: 1 (æå°)"
echo "   - Gradient Accumulation: 8 (æ¨¡æ‹Ÿ batch=8)"
echo "   - DeepSpeed ZeRO-2: å¯ç”¨"
echo "   - Mixed Precision: BF16"
echo "   - Precomputed Lang Embeds: å¯ç”¨"
echo "================================================"

# ä½¿ç”¨ accelerate å¯åŠ¨ï¼ˆå•æœºå•å¡ï¼‰
accelerate launch main.py \
    --deepspeed="./configs/zero2.json" \
    --pretrained_model_name_or_path="robotics-diffusion-transformer/rdt-1b" \
    --pretrained_text_encoder_name_or_path=$TEXT_ENCODER_NAME \
    --pretrained_vision_encoder_name_or_path=$VISION_ENCODER_NAME \
    --output_dir=$OUTPUT_DIR \
    --train_batch_size=1 \
    --gradient_accumulation_steps=8 \
    --sample_batch_size=1 \
    --max_train_steps=50000 \
    --checkpointing_period=2000 \
    --sample_period=1000 \
    --checkpoints_total_limit=10 \
    --lr_scheduler="constant" \
    --learning_rate=5e-5 \
    --mixed_precision="bf16" \
    --dataloader_num_workers=2 \
    --image_aug \
    --dataset_type="finetune" \
    --state_noise_snr=40 \
    --load_from_hdf5 \
    --precomp_lang_embed \
    --report_to=wandb

# å‚æ•°è¯´æ˜ï¼š
# --train_batch_size=1              # æ¯ä¸ªGPUçš„batch sizeè®¾ä¸º1ï¼ˆæœ€å°ï¼‰
# --gradient_accumulation_steps=8   # æ¢¯åº¦ç´¯ç§¯8æ­¥ï¼Œç›¸å½“äºbatch=8
# --sample_batch_size=1             # éªŒè¯æ—¶batch sizeä¹Ÿè®¾ä¸º1
# --learning_rate=5e-5              # é™ä½å­¦ä¹ ç‡ï¼ˆå› ä¸ºæœ‰æ•ˆbatch sizeæ›´å°ï¼‰
# --checkpointing_period=2000       # æ¯2000æ­¥ä¿å­˜ï¼ˆå‡å°‘ä¿å­˜é¢‘ç‡ï¼‰
# --checkpoints_total_limit=10      # åªä¿ç•™10ä¸ªcheckpoint
# --dataloader_num_workers=2        # å‡å°‘æ•°æ®åŠ è½½workers

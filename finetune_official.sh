#!/bin/bash

# æ¿€æ´» conda ç¯å¢ƒ
source ~/miniconda3/etc/profile.d/conda.sh
conda activate rdt

# æŒ‰ç…§å®˜æ–¹æ–‡æ¡£é…ç½®
export TEXT_ENCODER_NAME="google/t5-v1_1-xxl"
export VISION_ENCODER_NAME="google/siglip-so400m-patch14-384"
export OUTPUT_DIR="./checkpoints/rdt-170m-stack-blocks"
export WANDB_PROJECT="rdt-stack-blocks-finetune"
export WANDB_MODE="offline"

# PyTorch å†…å­˜ä¼˜åŒ–
export PYTORCH_CUDA_ALLOC_CONF="max_split_size_mb:128"

if [ ! -d "$OUTPUT_DIR" ]; then
    mkdir -p "$OUTPUT_DIR"
    echo "âœ… åˆ›å»ºè¾“å‡ºç›®å½•: '$OUTPUT_DIR'"
else
    echo "ğŸ“ è¾“å‡ºç›®å½•å·²å­˜åœ¨: '$OUTPUT_DIR'"
fi

# å•æœºè®­ç»ƒä¸éœ€è¦ hostfileï¼Œç›´æ¥ä½¿ç”¨ deepspeed
deepspeed --num_gpus=1 main.py \
    --deepspeed="./configs/zero2_offload.json" \
    --pretrained_model_name_or_path="robotics-diffusion-transformer/rdt-170m" \
    --pretrained_text_encoder_name_or_path=$TEXT_ENCODER_NAME \
    --pretrained_vision_encoder_name_or_path=$VISION_ENCODER_NAME \
    --output_dir=$OUTPUT_DIR \
    --train_batch_size=8 \
    --sample_batch_size=8 \
    --max_train_steps=50000 \
    --checkpointing_period=2000 \
    --sample_period=2000 \
    --checkpoints_total_limit=10 \
    --lr_scheduler="constant" \
    --learning_rate=1e-4 \
    --mixed_precision="bf16" \
    --dataloader_num_workers=2 \
    --image_aug \
    --dataset_type="finetune" \
    --state_noise_snr=40 \
    --load_from_hdf5 \
    --precomp_lang_embed \
    --report_to=wandb

# é’ˆå¯¹ 16GB æ˜¾å­˜çš„æ¿€è¿›ä¼˜åŒ–:
# - ä½¿ç”¨ zero2_offload.json (ä¼˜åŒ–å™¨å¸è½½åˆ° CPU)
# - train_batch_size: 1 (æœ€å°)
# - sample_batch_size: 1 (æœ€å°)
# - sample_period: 2000 (å‡å°‘éªŒè¯é¢‘ç‡)
# - dataloader_num_workers: 2 (å‡å°‘å†…å­˜å ç”¨)
# - checkpoints_total_limit: 10 (å‡å°‘ä¿å­˜æ•°é‡)
